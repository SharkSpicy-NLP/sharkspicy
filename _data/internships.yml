- role: LLM Research Intern
  organization: MEG, Baidu Inc.
  period: 2025.03-2025.08
  details: 'Architected scalable knowledge-to-KV cache mapping and attention retrieval training algorithms for LLMs, optimizing knowledge injection under tight computational constraints (resulted in <a href="https://arxiv.org/pdf/2511.06446" target="_blank" rel="noopener noreferrer">SR-KI</a> <span class="internship-venue-tag">AAAI 2026</span>).'

- role: NLP Research Intern
  organization: AI R&D Center, Beijing Wenge Technology Co., Ltd.
  period: 2024.04-2025.02
  details: 'Built high-quality TableQA and long-context QA benchmarks with automated evaluation pipelines, significantly improving model performance on key benchmarks (resulted in <a href="https://aclanthology.org/2025.emnlp-main.363.pdf" target="_blank" rel="noopener noreferrer">TableEval</a> <span class="internship-venue-tag">EMNLP 2025</span>).'