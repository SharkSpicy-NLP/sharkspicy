- role: LLM Research Intern
  organization: MEG, Baidu Inc.
  period: 2025.03-2025.08
  details: 'Developed scalable knowledge-to-KV cache mapping and attention training algorithms for LLMs, enabling efficient knowledge injection under computation constraints (resulted in <a href="https://arxiv.org/pdf/2511.06446" target="_blank" rel="noopener noreferrer">SR-KI</a> AAAI 2026).'

- role: NLP Research Intern
  organization: AI R&D Center, Beijing Wenge Technology Co., Ltd.
  period: 2024.04-2025.02
  details: 'Built high-quality TableQA and long-context QA benchmarks with automated evaluation pipelines, significantly improving model performance on key benchmarks (resulted in <a href="https://aclanthology.org/2025.emnlp-main.363.pdf" target="_blank" rel="noopener noreferrer">TableEval</a> EMNLP 2025).'